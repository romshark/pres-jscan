"{{Short description|Sequence of characters that forms a search pattern}}\\n{{Redirect|Regex|the comic book|Re:Gex{{!}}''Re:Gex''}}\\n{{Redirect|.*|the C++ operator|Pointer (computer science)#Pointer-to-member}}\\n[[File:Regular expression example.png|thumb|upright=1.5|{{legend|#b0d0e9|outline=#b0d0e9|text=Blue|highlights show the match results of the regular expression pattern: <syntaxhighlight lang=\"ragel\" inline>/h[aeiou]+/g</syntaxhighlight> (the letter ''h'' followed by one or more vowels)}}]]\\n\n\nA '''regular expression''' (shortened as '''regex''' or '''regexp''';<ref>{{cite web |url=http://www.regular-expressions.info/tutorial.html |title=Regular Expression Tutorial - Learn How to Use Regular Expressions |first=Jan |last=Goyvaerts |website=Regular-Expressions.info |access-date=2016-10-31 |archive-date=2016-11-01 |archive-url=https://web.archive.org/web/20161101212501/http://www.regular-expressions.info/tutorial.html }}</ref> sometimes referred to as '''rational expression'''<ref name=\"Mitkov2003\">{{cite book |first=Ruslan |last=Mitkov |title=The Oxford Handbook of Computational Linguistics |url=https://books.google.com/books?id=yl6AnaKtVAkC&pg=PA754 |date=2003 |publisher=Oxford University Press |isbn=978-0-19-927634-9 |page=754 |access-date=2016-07-25 |archive-date=2017-02-28 |archive-url=https://web.archive.org/web/20170228030346/https://books.google.com/books?id=yl6AnaKtVAkC&pg=PA754 |url-status=live }}</ref><ref name=\"Lawson2003\">{{cite book |first=Mark V. |last=Lawson |title=Finite Automata |url=https://books.google.com/books?id=MDQ_K7-z2AMC&pg=PA98 |date=17 September 2003 |publisher=CRC Press |isbn=978-1-58488-255-8 |pages=98–100 |access-date=25 July 2016 |archive-date=27 February 2017 |archive-url=https://web.archive.org/web/20170227195128/https://books.google.com/books?id=MDQ_K7-z2AMC&pg=PA98 |url-status=live }}</ref>) is a sequence of [[Character (computing)|characters]] that specifies a [[pattern matching|match pattern]] in [[String (computer science)|text]]. Usually such patterns are used by [[string-searching algorithm]]s for \"find\" or \"find and replace\" operations on [[String (computer science)|strings]], or for [[Data validation|input validation]]. Regular expression techniques are developed in [[theoretical computer science]] and [[formal language]] theory.\\n\n\nThe concept of regular expressions began in the 1950s, when the American mathematician [[Stephen Cole Kleene]] formalized the concept of a [[regular language]]. They came into common use with [[Unix]] text-processing utilities. Different [[Syntax (programming languages)|syntaxes]] for writing regular expressions have existed since the 1980s, one being the [[POSIX]] standard and another, widely used, being the [[Perl]] syntax.\\n\n\nRegular expressions are used in [[search engine]]s, in search and replace dialogs of [[word processor]]s and [[text editor]]s, in [[text processing]] utilities such as [[sed]] and [[AWK]], and in [[lexical analysis]]. Regular expressions are supported in many programming languages.\\n\n\n==History==\\n[[File:Kleene.jpg|thumb|upright|[[Stephen Cole Kleene]], who introduced the concept]]\\n\n\nRegular expressions originated in 1951, when mathematician [[Stephen Cole Kleene]] described [[regular language]]s using his mathematical notation called ''regular events''.{{sfn|Kleene|1951}}<ref name = \"Leung, New Mexico State University, 2010\" >{{Cite web | url=https://www.cs.nmsu.edu/historical-projects/Projects/kleene.9.16.10.pdf | title=Regular Languages and Finite Automata | access-date=13 August 2019 | first=Hing | last=Leung | date=16 September 2010 | website=[[New Mexico State University]] | quote=The concept of regular events was introduced by Kleene via the definition of regular expressions. | archive-url=https://web.archive.org/web/20131205193130/https://www.cs.nmsu.edu/historical-projects/Projects/kleene.9.16.10.pdf | archive-date=5 December 2013  | df=dmy-all }}</ref> These arose in [[theoretical computer science]], in the subfields of [[automata theory]] (models of computation) and the description and classification of [[formal language]]s. Other early implementations of [[pattern matching]] include the [[SNOBOL]] language, which did not use regular expressions, but instead its own pattern matching constructs.\\n\n\nRegular expressions entered popular use from 1968 in two uses: pattern matching in a text editor{{sfn|Thompson|1968}} and lexical analysis in a compiler.{{sfn|Johnson|Porter|Ackley|Ross|1968}} Among the first appearances of regular expressions in program form was when [[Ken Thompson]] built Kleene's notation into the editor [[QED (text editor)|QED]] as a means to match patterns in [[text file]]s.{{sfn|Thompson|1968}}<ref name=\"Beautiful Code Kernighan\">{{cite book | last1 = Kernighan | first1 = Brian | author-link1 = Brian Kernighan | title = Beautiful Code | chapter = A Regular Expressions Matcher | publisher = [[O'Reilly Media]] | pages = 1–2 | chapter-url = http://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html | access-date = 2013-05-15 | isbn = 978-0-596-51004-6 | date = 2007-08-08 | archive-date = 2020-10-07 | archive-url = https://web.archive.org/web/20201007183137/https://www.cs.princeton.edu/courses/archive/spr09/cos333/beautiful.html | url-status = live }}</ref><ref>{{cite web |url=http://cm.bell-labs.com/who/dmr/qed.html |title=An incomplete history of the QED Text Editor |last1=Ritchie |first1=Dennis M. |access-date=9 October 2013 |archive-url=https://web.archive.org/web/19990221023422/http://cm.bell-labs.com/who/dmr/qed.html |archive-date=1999-02-21 }}</ref>{{sfn|Aho|Ullman|1992|loc=10.11 Bibliographic Notes for Chapter 10, p. 589}} For speed, Thompson implemented regular expression matching by [[just-in-time compilation]] (JIT) to [[IBM 7094]] code on the [[Compatible Time-Sharing System]], an important early example of JIT compilation.{{sfn|Aycock|2003|p=98}} He later added this capability to the Unix editor [[ed (text editor)|ed]], which eventually led to the popular search tool [[grep]]'s use of regular expressions (\"grep\" is a word derived from the command for regular expression searching in the ed editor: <code>g/''re''/p</code> meaning \"Global search for Regular Expression and Print matching lines\").<ref>{{cite web |url=http://catb.org/jargon/html/G/grep.html |title=Jargon File 4.4.7: grep |author=[[Eric S. Raymond|Raymond, Eric S.]] citing [[Dennis Ritchie]] |date=2003 |access-date=2009-02-17 |archive-date=2011-06-05 |archive-url=https://web.archive.org/web/20110605165512/http://www.catb.org/jargon/html/G/grep.html }}</ref> Around the same time when Thompson developed QED, a group of researchers including [[Douglas T. Ross]] implemented a tool based on regular expressions that is used for lexical analysis in [[compiler]] design.{{sfn|Johnson|Porter|Ackley|Ross|1968}}\\n\n\nMany variations of these original forms of regular expressions were used in [[Unix]]{{sfn|Aho|Ullman|1992|loc=10.11 Bibliographic Notes for Chapter 10, p. 589}} programs at [[Bell Labs]] in the 1970s, including [[vi]], [[Lex programming tool|lex]], [[sed]], [[AWK]], and [[expr]], and in other programs such as [[Emacs]] (which has its own, incompatible syntax and behavior). Regexes were subsequently adopted by a wide range of programs, with these early forms standardized in the [[POSIX.2]] standard in 1992.\\n\n\nIn the 1980s, the more complicated regexes arose in [[Perl]], which originally derived from a regex library written by [[Henry Spencer]] (1986), who later wrote an implementation for [[Tcl]] called ''Advanced Regular Expressions''.<ref>{{cite web | url = http://www.tcl.tk/doc/howto/regexp81.html | title = New Regular Expression Features in Tcl 8.1 | access-date = 2013-10-11 | archive-date = 2020-10-07 | archive-url = https://web.archive.org/web/20201007183137/http://www.tcl.tk/doc/howto/regexp81.html | url-status = live }}</ref> The Tcl library is a hybrid [[Nondeterministic finite automaton|NFA]]/[[Deterministic finite automaton|DFA]] implementation with improved performance characteristics. Software projects that have adopted Spencer's Tcl regular expression implementation include [[PostgreSQL]].<ref>{{cite web | url = http://www.postgresql.org/docs/9.3/interactive/functions-matching.html | title = PostgreSQL 9.3.1 Documentation: 9.7. Pattern Matching | access-date = 2013-10-12 | archive-date = 2020-10-07 | archive-url = https://web.archive.org/web/20201007183140/https://www.postgresql.org/docs/9.3/functions-matching.html | url-status = live }}</ref> Perl later expanded on Spencer's original library to add many new features.<ref>{{cite web |url=http://perldoc.perl.org/perlre.html |title=perlre: Perl Regular Expressions |author=[[Larry Wall|Wall, Larry]] and the Perl 5 development team |date=2006 |access-date=2006-10-10 |archive-date=2009-12-31 |archive-url=https://web.archive.org/web/20091231010052/http://perldoc.perl.org/perlre.html |url-status=live }}</ref> Part of the effort in the design of [[Raku (programming language)|Raku]] (formerly named Perl 6) is to improve Perl's regex integration, and to increase their scope and capabilities to allow the definition of [[parsing expression grammar]]s.<ref name=\"Apocalypse5\">{{harvtxt|Wall|2002}}</ref> The result is a [[mini-language]] called [[Raku rules]], which are used to define Raku grammar as well as provide a tool to programmers in the language. These rules maintain existing features of Perl 5.x regexes, but also allow [[Backus–Naur form|BNF]]-style definition of a [[recursive descent parser]] via sub-rules.\\n\n\nThe use of regexes in structured information standards for document and database modeling started in the 1960s and expanded in the 1980s when industry standards like [[Standard Generalized Markup Language|ISO SGML]] (precursored by ANSI \"GCA 101-1983\") consolidated. The kernel of the [[XML schema#Validation|structure specification language]] standards consists of regexes. Its use is evident in the [[Document Type Definition|DTD]] element group syntax. Prior to the use of regular expressions, many search languages allowed simple wildcards, for example \"*\" to match any sequence of characters, and \"?\" to match a single character. Relics of this can be found today in the [[glob (programming)|glob]] syntax for filenames, and in the [[SQL]] <code>LIKE</code> operator.\\n\n\nStarting in 1997, [[Philip Hazel]] developed [[Perl Compatible Regular Expressions|PCRE]] (Perl Compatible Regular Expressions), which attempts to closely mimic Perl's regex functionality and is used by many modern tools including [[PHP]] and [[Apache HTTP Server]].{{cn|date=June 2022}}\\n\n\nToday, regexes are widely supported in programming languages, text processing programs (particularly [[lexer]]s), advanced text editors, and some other programs. Regex support is part of the [[standard library]] of many programming languages, including [[Java (programming language)|Java]] and [[Python (programming language)|Python]], and is built into the syntax of others, including Perl and [[ECMAScript]]. Implementations of regex functionality is often called a '''regex engine''', and a number of libraries are available for reuse. In the late 2010s, several companies started to offer hardware, [[FPGA]],<ref>{{Cite web |url=https://grovf.com/products/gregex |title=GRegex – Faster Analytics for Unstructured Text Data |website=grovf.com |access-date=2019-10-22 |archive-date=2020-10-07 |archive-url=https://web.archive.org/web/20201007183139/https://grovf.com/products/gregex |url-status=live }}</ref> [[GPU]]<ref>{{Cite web|url=http://bkase.github.io/CUDA-grep/finalreport.html|title=CUDA grep|website=bkase.github.io|access-date=2019-10-22|archive-date=2020-10-07|archive-url=https://web.archive.org/web/20201007183138/http://bkase.github.io/CUDA-grep/finalreport.html|url-status=live}}</ref> implementations of [[PCRE]] compatible '''regex engines''' that are faster compared to [[Central processing unit|CPU]] implementations'''.'''\\n\n\n==Patterns==\\nThe phrase ''regular expressions'', or ''regexes'', is often used to mean the specific, standard textual syntax for representing patterns for matching text, as distinct from the mathematical notation described below. Each character in a regular expression (that is, each character in the string describing its pattern) is either a [[metacharacter]], having a special meaning, or a regular character that has a literal meaning. For example, in the regex <code>b.</code>, 'b' is a literal character that matches just 'b', while '.' is a metacharacter that matches every character except a newline. Therefore, this regex matches, for example, 'b%', or 'bx', or 'b5'. Together, metacharacters and literal characters can be used to identify text of a given pattern or process a number of instances of it. Pattern matches may vary from a precise equality to a very general similarity, as controlled by the metacharacters. For example, <code>.</code> is a very general pattern, <code><nowiki>[a-z]</nowiki></code> (match all lower case letters from 'a' to 'z') is less general and <code>b</code> is a precise pattern (matches just 'b'). The metacharacter syntax is designed specifically to represent prescribed targets in a concise and flexible way to direct the automation of text processing of a variety of input data, in a form easy to type using a standard [[ASCII]] [[Computer keyboard|keyboard]].\\n\n\nA very simple case of a regular expression in this syntax is to locate a word spelled two different ways in a [[text editor]], the regular expression <code>seriali[sz]e</code> matches both \"serialise\" and \"serialize\". [[Wildcard character]]s also achieve this, but are more limited in what they can pattern, as they have fewer metacharacters and a simple language-base.\\n\n\nThe usual context of wildcard characters is in [[Glob (programming)|globbing]] similar names in a list of files, whereas regexes are usually employed in applications that pattern-match text strings in general. For example, the regex <syntaxhighlight lang=\"ragel\" inline>^[ \\\\t]+|[ \\\\t]+$</syntaxhighlight> matches excess whitespace at the beginning or end of a line. An advanced regular expression that matches any numeral is <syntaxhighlight lang=\"ragel\" inline>[+-]?(\\\\d+(\\\\.\\\\d*)?|\\\\.\\\\d+)([eE][+-]?\\\\d+)?</syntaxhighlight>.\\n\n\n[[File:Thompson-kleene-star.svg|right|thumb|[[Thompson's construction algorithm|Translating]] the [[Kleene star]]<br />(''s''* means \"zero or more of ''s''\")]]\\nA '''regex processor''' translates a regular expression in the above syntax into an internal representation that can be executed and matched against a [[string (computing)|string]] representing the text being searched in. One possible approach is the [[Thompson's construction algorithm]] to construct a [[nondeterministic finite automaton]] (NFA), which is then [[Powerset construction|made deterministic]] and the resulting [[deterministic finite automaton]] (DFA) is run on the target text string to recognize substrings that match the regular expression.\\nThe picture shows the NFA scheme <code>''N''(''s''*)</code> obtained from the regular expression <code>''s''*</code>, where ''s'' denotes a simpler regular expression in turn, which has already been [[Recursion (computer science)|recursively]] translated to the NFA ''N''(''s'').\\n\n\n==Basic concepts==\\nA regular expression, often called a ''pattern'', specifies a [[Set (computer science)|set]] of strings required for a particular purpose. A simple way to specify a finite set of strings is to list its [[Data element|elements]] or members. However, there are often more concise ways: for example, the set containing the three strings \"Handel\", \"Händel\", and \"Haendel\" can be specified by the pattern <code>H(ä|ae?)ndel</code>; we say that this pattern ''matches'' each of the three strings. However, there can be many ways to write a regular expression for the same set of strings: for example, <code>(Hän|Han|Haen)del</code> also specifies the same set of three strings in this example.\\n\n\nMost formalisms provide the following operations to construct regular expressions.\\n\n\n; Boolean \"or\"\\n: A [[vertical bar]] separates alternatives. For example, {{code|lang=perl|code=gray{{!}}grey}} can match \"gray\" or \"grey\".\\n; Grouping\\n: [[Parentheses]] are used to define the scope and precedence of the [[Operator (programming)|operators]] (among other uses). For example, <code>gray|grey</code> and {{code|lang=perl|code=gr(a{{!}}e)y}} are equivalent patterns which both describe the set of \"gray\" or \"grey\".\\n; Quantification\\n: A [[Quantifier (linguistics)|quantifier]] after an element (such as a [[Lexical analysis#Token|token]], character, or group) specifies how many times the preceding element is allowed to repeat. The most common quantifiers are the [[question mark]] <code>?</code>, the [[asterisk]] <code>*</code> (derived from the [[Kleene star]]), and the [[plus sign]] <code>+</code> ([[Kleene plus]]).\\n: {|\\n|-\\n| style=\"width:15px; vertical-align:top;\" | <code>'''?'''</code>\\n|The question mark indicates ''zero or one'' occurrences of the preceding element. For example, <code><!--DON'T CHANGE THIS TO \"colo?r\"; REGULAR EXPRESSIONS DON'T WORK LIKE WILDCARDS!-->colou?r</code> matches both \"color\" and \"colour\".\\n|-\\n| style=\"vertical-align:top;\" | <code>'''<nowiki>*</nowiki>'''</code>\\n|The asterisk indicates ''zero or more'' occurrences of the preceding element. For example, <code>ab*c</code> matches \"ac\", \"abc\", \"abbc\", \"abbbc\", and so on.\\n|-\\n| style=\"vertical-align:top;\" | <code>'''+'''</code>\\n|The plus sign indicates ''one or more'' occurrences of the preceding element. For example, <code>ab+c</code> matches \"abc\", \"abbc\", \"abbbc\", and so on, but not \"ac\".\\n|-\\n|<code>'''{n}'''</code><ref name=\"grep\">{{cite web |last=Kerrisk |first=Michael |title=grep(1) - Linux manual page |url=https://man7.org/linux/man-pages/man1/grep.1.html |website=man7.org |access-date=31 January 2023}}</ref>\\n| The preceding item is matched exactly ''n'' times.\\n|-\\n|<code>'''{min,}'''</code><ref name=\"grep\"/>\\n| The preceding item is matched ''min'' or more times.\\n|-\\n|<code>'''{,max}'''</code><ref name=\"grep\"/>\\n| The preceding item is matched up to ''max'' times.\\n|-\\n|<code>'''{min,max}'''</code><ref name=\"grep\"/>\\n| The preceding item is matched at least ''min'' times, but not more than ''max'' times.\\n|}\\n; Wildcard\\n: The wildcard <code>'''.'''</code> matches any character. For example,\\n::<code>a.b</code> matches any string that contains an \"a\", and then any character and then \"b\".\\n::<code>a.*b</code> matches any string that contains an \"a\", and then the character \"b\" at some later point.\\n\n\nThese constructions can be combined to form arbitrarily complex expressions, much like one can construct arithmetical expressions from numbers and the operations +, −, ×, and ÷.\\n\n\nThe precise [[syntax]] for regular expressions varies among tools and with context; more detail is given in {{slink||Syntax}}.\\n\n\n==Formal language theory==\\nRegular expressions describe [[regular language]]s in [[Formal language|formal language theory]]. They have the same expressive power as [[regular grammar]]s.\\n\n\n===Formal definition===\\nRegular expressions consist of constants, which denote sets of strings, and operator symbols, which denote operations over these sets. The following definition is standard, and found as such in most textbooks on formal language theory.<ref name=\"HopcroftMotwaniUllman01\">{{harvtxt|Hopcroft|Motwani|Ullman|2000}}</ref><ref>{{harvtxt|Sipser|1998}}</ref> Given a finite [[alphabet (computer science)|alphabet]] Σ, the following constants are defined\\nas regular expressions:\\n* (''empty set'') ∅ denoting the set ∅.\\n* (''[[empty string]]'') ε denoting the set containing only the \"empty\" string, which has no characters at all.\\n* (''[[string literal|literal character]]'') <code>a</code> in Σ denoting the set containing only the character ''a''.\\n\n\nGiven regular expressions R and S, the following operations over them are defined\\nto produce regular expressions:\\n* (''[[concatenation]]'') <code>(RS)</code> denotes the set of strings that can be obtained by concatenating a string accepted by R and a string accepted by S (in that order). For example, let R denote {\"ab\", \"c\"} and S denote {\"d\", \"ef\"}. Then, <code>(RS)</code> denotes {\"abd\", \"abef\", \"cd\", \"cef\"}.\\n* (''[[alternation (formal language theory)|alternation]]'') <code>(R|S)</code> denotes the [[set union]] of sets described by R and S. For example, if R describes {\"ab\", \"c\"} and S describes {\"ab\", \"d\", \"ef\"}, expression <code>(R|S)</code> describes {\"ab\", \"c\", \"d\", \"ef\"}.\\n* (''[[Kleene star]]'') <code>(R*)</code> denotes the smallest [[subset|superset]] of the set described by ''R'' that contains ε and is [[Closure (mathematics)|closed]] under string concatenation. This is the set of all strings that can be made by concatenating any finite number (including zero) of strings from the set described by R. For example, if R denotes {\"0\", \"1\"}, <code>(R*)</code> denotes the set of all finite [[binary string]]s (including the empty string). If R denotes {\"ab\", \"c\"}, <code>(R*)</code> denotes {ε, \"ab\", \"c\", \"abab\", \"abc\", \"cab\", \"cc\", \"ababab\", \"abcab\", ...}.\\n\n\nTo avoid parentheses, it is assumed that the Kleene star has the highest priority followed by concatenation, then alternation. If there is no ambiguity, then parentheses may be omitted. For example, <code>(ab)c</code> can be written as <code>abc</code>, and <code>a|(b(c*))</code> can be written as <code>a|bc*</code>. Many textbooks use the symbols ∪, +, or ∨ for alternation instead of the vertical bar.\\n\n\n'''Examples:'''\\n* <code>a|b*</code> denotes {ε, \"a\", \"b\", \"bb\", \"bbb\", ...}\\n* <code>(a|b)*</code> denotes the set of all strings with no symbols other than \"a\" and \"b\", including the empty string: {ε, \"a\", \"b\", \"aa\", \"ab\", \"ba\", \"bb\", \"aaa\", ...}\\n* <code>ab*(c|ε)</code> denotes the set of strings starting with \"a\", then zero or more \"b\"s and finally optionally a \"c\": {\"a\", \"ac\", \"ab\", \"abc\", \"abb\", \"abbc\", ...}\\n* <code>(0|(1(01*0)*1))*</code> denotes the set of binary numbers that are multiples of 3: { ε, \"0\", \"00\", \"11\", \"000\", \"011\", \"110\", \"0000\", \"0011\", \"0110\", \"1001\", \"1100\", \"1111\", \"00000\", ... }\\n\n\n===Expressive power and compactness===\\nThe formal definition of regular expressions is minimal on purpose, and avoids defining <code>?</code> and <code>+</code>—these can be expressed as follows: <code>a+</code> = <code>aa*</code>, and <code>a?</code> = <code>(a|ε)</code>. Sometimes the [[set complement|complement]] operator is added, to give a ''generalized regular expression''; here ''R<sup>c</sup>'' matches all strings over Σ* that do not match ''R''. In principle, the complement operator is redundant, because it doesn't grant any more expressive power. However, it can make a regular expression much more concise—eliminating a single complement operator can cause a [[Double exponential function|double exponential]] blow-up of its length.<ref>{{harvtxt|Gelade|Neven|2008|p=332|loc=Thm.4.1}}</ref><ref>{{harvtxt|Gruber|Holzer|2008}}</ref><ref>Based on {{harvtxt|Gelade|Neven|2008}}, a regular expression of length about 850 such that its complement has a length  about 2<sup>32</sup> can be found at [[:File:RegexComplementBlowup.png]].</ref>\\n\n\nRegular expressions in this sense can express the regular languages, exactly the class of languages accepted by [[deterministic finite automata]]. There is, however, a significant difference in compactness. Some classes of regular languages can only be described by deterministic finite automata whose size grows [[exponential growth|exponentially]] in the size of the shortest equivalent regular expressions. The standard example here is the languages\\n''L<sub>k</sub>'' consisting of all strings over the alphabet {''a'',''b''} whose ''k''<sup>th</sup>-from-last letter equals&nbsp;''a''. On the one hand, a regular expression describing ''L''<sub>4</sub> is given by\\n<math>(a\\\\mid b)^*a(a\\\\mid b)(a\\\\mid b)(a\\\\mid b)</math>.\\n\n\nGeneralizing this pattern to ''L<sub>k</sub>'' gives the expression:\\n<math>(a\\\\mid b)^*a\\\\underbrace{(a\\\\mid b)(a\\\\mid b)\\\\cdots(a\\\\mid b)}_{k-1\\\\text{ times}}. \\\\, </math>\\n\n\nOn the other hand, it is known that every deterministic finite automaton accepting the language ''L<sub>k</sub>'' must have at least 2<sup>''k''</sup> states. Luckily, there is a simple mapping from regular expressions to the more general [[nondeterministic finite automata]] (NFAs) that does not lead to such a blowup in size; for this reason NFAs are often used as alternative representations of regular languages. NFAs are a simple variation of the type-3 [[formal grammar|grammars]] of the [[Chomsky hierarchy]].<ref name=\"HopcroftMotwaniUllman01\"/>\\n\n\nIn the opposite direction, there are many languages easily described by a DFA that are not easily described by a regular expression. For instance, determining the validity of a given [[ISBN]] requires computing the modulus of the integer base 11, and can be easily implemented with an 11-state DFA. However, a regular expression to answer the same problem of divisibility by 11 is at least multiple megabytes in length.{{citation needed|date=February 2018}}\\n\n\nGiven a regular expression, [[Thompson's construction algorithm]] computes an equivalent nondeterministic finite automaton. A conversion in the opposite direction is achieved by [[Kleene's algorithm]].\\n\n\nFinally, it is worth noting that many real-world \"regular expression\" engines implement features that cannot be described by the regular expressions in the sense of formal language theory; rather, they implement ''regexes''. See [[#Patterns for non-regular languages|below]] for more on this.\\n\n\n===Deciding equivalence of regular expressions===\\nAs seen in many of the examples above, there is more than one way to construct a regular expression to achieve the same results.\\n\n\nIt is possible to write an [[algorithm]] that, for two given regular expressions, decides whether the described languages are equal; the algorithm reduces each expression to a [[minimal deterministic finite state machine]], and determines whether they are [[Isomorphism|isomorphic]] (equivalent).\\n\n\nAlgebraic laws for regular expressions can be obtained using a method by Gischer which is best explained along an example: In order to check whether (''X''+''Y'')<sup>*</sup> and (''X''<sup>*</sup> ''Y''<sup>*</sup>)<sup>*</sup> denote the same regular language, for all regular expressions ''X'', ''Y'', it is necessary and sufficient to check whether the particular regular expressions (''a''+''b'')<sup>*</sup> and (''a''<sup>*</sup> ''b''<sup>*</sup>)<sup>*</sup> denote the same language over the alphabet Σ={''a'',''b''}. More generally, an equation ''E''=''F'' between regular-expression terms with variables holds if, and only if, its instantiation with different variables replaced by different symbol constants holds.<ref>{{cite report |first=Jay L. |last=Gischer |institution=Stanford Univ., Dept. of Comp. Sc. |title=(Title unknown) |type=Technical Report |number=STAN-CS-TR-84-1033 |date=1984 }}{{Title missing|date=February 2023}}</ref><ref>{{cite book |isbn=978-0-201-44124-6 |first1=John E. |last1=Hopcroft |first2=Rajeev |last2=Motwani |first3=Jeffrey D. |last3=Ullman |name-list-style=amp |title=Introduction to Automata Theory, Languages, and Computation |location=Upper Saddle River, New Jersey |publisher=Addison Wesley |date=2003 |pages=117–120 |quote=This property need not hold for extended regular expressions, even if they describe no larger class than regular languages; cf. p.121. }}</ref>\\n\n\nEvery regular expression can be written solely in terms of the [[Kleene star]] and [[Union (set theory)|set unions]] over finite words. This is a surprisingly difficult problem. As simple as the regular expressions are, there is no method to systematically rewrite them to some normal form. The lack of axiom in the past led to the [[star height problem]]. In 1991, [[Dexter Kozen]] axiomatized regular expressions as a [[Kleene algebra#History|Kleene algebra]], using equational and [[Horn clause]] axioms.<ref>{{harvtxt|Kozen|1991}}{{page needed|date=February 2015}}</ref>\\nAlready in 1964, Redko had proved that no finite set of purely equational axioms can characterize the algebra of regular languages.<ref>{{cite journal |first=V.N. |last=Redko |url=http://umj.imath.kiev.ua/article/?article=10002 |title=On defining relations for the algebra of regular events |journal=Ukrainskii Matematicheskii Zhurnal |date=1964 |volume=16 |number=1 |pages=120–126 |access-date=2018-03-28 |archive-date=2018-03-29 |archive-url=https://web.archive.org/web/20180329121016/http://umj.imath.kiev.ua/article/?article=10002 |url-status=live |language=Russian }}</ref>\\n\n\n==Syntax==\\n<!-- 'Google Codesearch FAQ' links here. -->\\nA regex ''pattern'' matches a target ''string''. The pattern is composed of a sequence of ''atoms''. An atom is a single point within the regex pattern which it tries to match to the target string. The simplest atom is a literal, but grouping parts of the pattern to match an atom will require using <code>(&nbsp;)</code> as metacharacters. Metacharacters help form: ''atoms''; ''quantifiers'' telling how many atoms (and whether it is a [[#Lazy matching|''greedy'' quantifier]] or not); a logical OR character, which offers a set of alternatives, and a logical NOT character, which negates an atom's existence; and backreferences to refer to previous atoms of a completing pattern of atoms. A match is made, not when all the atoms of the string are matched, but rather when all the pattern atoms in the regex have matched. The idea is to make a small pattern of characters stand for a large number of possible strings, rather than compiling a large list of all the literal possibilities.\\n\n\nDepending on the regex processor there are about fourteen metacharacters, characters that may or may not have their [[Literal (computer programming)|literal]] character meaning, depending on context, or whether they are \"escaped\", i.e. preceded by an [[escape sequence]], in this case, the backslash <code>\\\\</code>. Modern and POSIX extended regexes use metacharacters more often than their literal meaning, so to avoid \"backslash-osis\" or [[leaning toothpick syndrome]] it makes sense to have a metacharacter escape to a literal mode; but starting out, it makes more sense to have the four bracketing metacharacters <code>(&nbsp;)</code> and <code>{&nbsp;}</code> be primarily literal, and \"escape\" this usual meaning to become metacharacters. Common standards implement both. The usual metacharacters are <code> {}[]()^$.|*+?</code> and <code>\\\\</code>. The usual characters that become metacharacters when escaped are <code>dswDSW</code> and <code>N</code>.\\n\n\n===Delimiters===\\nWhen entering a regex in a programming language, they may be represented as a usual string literal, hence usually quoted; this is common in C, Java, and Python for instance, where the regex <code>re</code> is entered as <code>\"re\"</code>. However, they are often written with slashes as [[delimiter]]s, as in <code>/re/</code> for the regex <code>re</code>. This originates in [[Ed (text editor)|ed]], where <code>/</code> is the editor command for searching, and an expression <code>/re/</code> can be used to specify a range of lines (matching the pattern), which can be combined with other commands on either side, most famously <code>g/re/p</code> as in [[grep]] (\"global regex print\"), which is included in most [[Unix]]-based operating systems, such as [[Linux]] distributions. A similar convention is used in [[sed]], where search and replace is given by <code>s/re/replacement/</code> and patterns can be joined with a comma to specify a range of lines as in <code>/re1/,/re2/</code>. This notation is particularly well known due to its use in [[Perl]], where it forms part of the syntax distinct from normal string literals. In some cases, such as sed and Perl, alternative delimiters can be used to avoid collision with contents, and to avoid having to escape occurrences of the delimiter character in the contents. For example, in sed the command <code>s,/,X,</code> will replace a <code>/</code> with an <code>X</code>, using commas as delimiters.\\n\n\n===Standards<span class=\"anchor\" id=\"POSIX\"></span>===\\nThe [[Institute of Electrical and Electronics Engineers|IEEE]] [[POSIX]] standard has three sets of compliance: '''BRE''' (Basic Regular Expressions),<ref>ISO/IEC 9945-2:1993 ''Information technology – Portable Operating System Interface (POSIX) – Part 2: Shell and Utilities'', successively revised as ISO/IEC 9945-2:2002 ''Information technology – Portable Operating System Interface (POSIX) – Part 2: System Interfaces'', ISO/IEC 9945-2:2003, and currently ISO/IEC/IEEE 9945:2009 ''Information technology – Portable Operating System Interface (POSIX) Base Specifications, Issue 7''</ref> '''ERE''' (Extended Regular Expressions), and '''SRE''' (Simple Regular Expressions). SRE is [[Deprecation|deprecated]],<ref>The Single Unix Specification (Version 2)</ref> in favor of BRE, as both provide [[backward compatibility]]. The subsection below covering the ''character classes'' applies to both BRE and ERE.\\n\n\nBRE and ERE work together. ERE adds <code>?</code>, <code>+</code>, and <code>|</code>, and it removes the need to escape the metacharacters <code>(&nbsp;)</code> and <code>{&nbsp;}</code>, which are ''required'' in BRE. Furthermore, as long as the POSIX standard syntax for regexes is adhered to, there can be, and often is, additional syntax to serve specific (yet POSIX compliant) applications. Although POSIX.2 leaves some implementation specifics undefined, BRE and ERE provide a \"standard\" which has since been adopted as the default syntax of many tools, where the choice of BRE or ERE modes is usually a supported option. For example, [[GNU]] <code>grep</code> has the following options: \"<code>grep -E</code>\" for ERE, and \"<code>grep -G</code>\" for BRE (the default), and \"<code>grep -P</code>\" for [[Perl]] regexes.\\n\n\nPerl regexes have become a de facto standard, having a rich and powerful set of atomic expressions. Perl has no \"basic\" or \"extended\" levels. As in POSIX EREs, <code>(&nbsp;)</code> and <code>{&nbsp;}</code> are treated as metacharacters unless escaped; other metacharacters are known to be literal or symbolic based on context alone. Additional functionality includes [[#Lazy matching|lazy matching]], [[#backreferences|backreferences]], named capture groups, and [[Recursion (computer science)|recursive]] patterns.\\n\n\n====POSIX basic and extended====\\nIn the [[POSIX]] standard, Basic Regular Syntax ('''BRE''') requires that the [[metacharacter]]s <code>(&nbsp;)</code> and <code>{&nbsp;}</code> be designated <code>\\\\(\\\\)</code> and <code>\\\\{\\\\}</code>, whereas Extended Regular Syntax ('''ERE''') does not.\\n\n\n{| class=\"wikitable\"\\n|-\\n! Metacharacter\\n! Description\\n|- valign=\"top\"\\n!<code>^</code>\\n|Matches the starting position within the string. In line-based tools, it matches the starting position of any line.\\n|- valign=\"top\"\\n!<code>.</code>\\n|Matches any single character (many applications exclude [[newline]]s, and exactly which characters are considered newlines is flavor-, character-encoding-, and platform-specific, but it is safe to assume that the line feed character is included). Within POSIX bracket expressions, the dot character matches a literal dot. For example, <code>a.c</code> matches \"abc\", etc., but <code>[a.c]</code> matches only \"a\", \".\", or \"c\".\\n|- valign=\"top\"\\n!<code>[&nbsp;]</code>\\n|A bracket expression. Matches a single character that is contained within the brackets. For example, <code>[abc]</code> matches \"a\", \"b\", or \"c\". <code>[a-z]</code> specifies a range which matches any lowercase letter from \"a\" to \"z\". These forms can be mixed: <code>[abcx-z]</code> matches \"a\", \"b\", \"c\", \"x\", \"y\", or \"z\", as does <code>[a-cx-z]</code>.\\nThe <code>-</code> character is treated as a literal character if it is the last or the first (after the <code>^</code>, if present) character within the brackets: <code>[abc-]</code>, <code>[-abc]</code>. Note that backslash escapes are not allowed. The <code>]</code> character can be included in a bracket expression if it is the first (after the <code>^</code>) character: <code>[]abc]</code>.\\n|- valign=\"top\"\\n!<code>[^&nbsp;]</code>\\n|Matches a single character that is not contained within the brackets. For example, <code>[^abc]</code> matches any character other than \"a\", \"b\", or \"c\". <code>[^a-z]</code> matches any single character that is not a lowercase letter from \"a\" to \"z\". Likewise, literal characters and ranges can be mixed.\\n|- valign=\"top\"\\n!<code>$</code>\\n|Matches the ending position of the string or the position just before a string-ending newline. In line-based tools, it matches the ending position of any line.\\n|- valign=\"top\"\\n!<code>( )</code>\\n|Defines a marked subexpression. The string matched within the parentheses can be recalled later (see the next entry, <code>\\\\''n''</code>). A marked subexpression is also called a block or capturing group. '''BRE mode requires {{nowrap|<code>\\\\(&nbsp;\\\\)</code>}}'''.\\n|- valign=\"top\"\\n!<code>\\\\''n''</code>\\n|Matches what the ''n''th marked subexpression matched, where ''n'' is a digit from 1 to 9. This construct is vaguely defined in the POSIX.2 standard. Some tools allow referencing more than nine capturing groups. Also known as a backreference. '''backreferences are only supported in BRE mode'''\\n|- valign=\"top\"\\n!<code>*</code>\\n|Matches the preceding element zero or more times. For example, <code>ab*c</code> matches \"ac\", \"abc\", \"abbbc\", etc. <code>[xyz]*</code> matches \"\", \"x\", \"y\", \"z\", \"zx\", \"zyx\", \"xyzzy\", and so on. <code>(ab)*</code> matches \"\", \"ab\", \"abab\", \"ababab\", and so on.\\n|- valign=\"top\"\\n!{{nowrap|<code>{''m'',''n''}</code>}}\\n|Matches the preceding element at least ''m'' and not more than ''n'' times. For example, <code>a{3,5}</code> matches only \"aaa\", \"aaaa\", and \"aaaaa\". This is not found in a few older instances of regexes. '''BRE mode requires <code>{{nowrap|\\\\{''m'',''n''\\\\}}}</code>'''.\\n\n\n|}\\n\n\n'''Examples:'''\\n* <code>.at</code> matches any three-character string ending with \"at\", including \"hat\", \"cat\", \"bat\", \"4at\", \"#at\" and \" at\" (starting with a space).\\n* <code>[hc]at</code> matches \"hat\" and \"cat\".\\n* <code>[^b]at</code> matches all strings matched by <code>.at</code> except \"bat\".\\n* <code>[^hc]at</code> matches all strings matched by <code>.at</code> other than \"hat\" and \"cat\".\\n* <code>^[hc]at</code> matches \"hat\" and \"cat\", but only at the beginning of the string or line.\\n* <code>[hc]at$</code> matches \"hat\" and \"cat\", but only at the end of the string or line.\\n* <code>\\\\[.\\\\]</code> matches any single character surrounded by \"[\" and \"]\" since the brackets are escaped, for example: \"[a]\", \"[b]\", \"[7]\", \"[@]\", \"[]]\", and \"[ ]\" (bracket space bracket).\\n* <code>s.*</code> matches s followed by zero or more characters, for example: \"s\", \"saw\", \"seed\", \"s3w96.7\", and \"s6#h%(>>>m n mQ\".\\n\n\n====POSIX extended====\\nThe meaning of metacharacters [[escape character|escaped]] with a backslash is reversed for some characters in the POSIX Extended Regular Expression ('''ERE''') syntax. With this syntax, a backslash causes the metacharacter to be treated as a literal character. So, for example, <code>\\\\(&nbsp;\\\\)</code> is now <code>(&nbsp;)</code> and <code>\\\\{&nbsp;\\\\}</code> is now <code>{&nbsp;}</code>. Additionally, support is removed for <code>\\\\''n''</code> backreferences and the following metacharacters are added:\\n\n\n{| class=\"wikitable\"\\n|-\\n! Metacharacter\\n! Description\\n|- valign=\"top\"\\n! <code>?</code>\\n| Matches the preceding element zero or one time. For example, <code>ab?c</code> matches only \"ac\" or \"abc\".\\n|-\\n! <code>+</code>\\n| Matches the preceding element one or more times. For example, <code>ab+c</code> matches \"abc\", \"abbc\", \"abbbc\", and so on, but not \"ac\".\\n|-\\n! <code><nowiki>|</nowiki></code>\\n| The choice (also known as alternation or set union) operator matches either the expression before or the expression after the operator. For example, <code><nowiki>abc|def</nowiki></code> matches \"abc\" or \"def\".\\n|}\\n\n\n'''Examples:'''\\n* <code>[hc]?at</code> matches \"at\", \"hat\", and \"cat\".\\n* <code>[hc]*at</code> matches \"at\", \"hat\", \"cat\", \"hhat\", \"chat\", \"hcat\", \"cchchat\", and so on.\\n* <code>[hc]+at</code> matches \"hat\", \"cat\", \"hhat\", \"chat\", \"hcat\", \"cchchat\", and so on, but not \"at\".\\n* <code>cat|dog</code> matches \"cat\" or \"dog\".\\n\n\nPOSIX Extended Regular Expressions can often be used with modern Unix utilities by including the [[command line]] flag <var>-E</var>.\\n\n\n====Character classes====\\nThe character class is the most basic regex concept after a literal match. It makes one small sequence of characters match a larger set of characters. For example, <syntaxhighlight lang=\"ragel\" inline>[A-Z]</syntaxhighlight> could stand for any uppercase letter in the English alphabet, and <syntaxhighlight lang=\"ragel\" inline>\\\\d</syntaxhighlight> could mean any digit. Character classes apply to both POSIX levels.\\n\n\nWhen specifying a range of characters, such as <syntaxhighlight lang=\"ragel\" inline>[a-Z]</syntaxhighlight> (i.e. lowercase ''<syntaxhighlight lang=\"ragel\" inline>a</syntaxhighlight>'' to uppercase ''<syntaxhighlight lang=\"ragel\" inline>Z</syntaxhighlight>''), the computer's locale settings determine the contents by the numeric ordering of the character encoding. They could store digits in that sequence, or the ordering could be ''abc…zABC…Z'', or ''aAbBcC…zZ''. So the POSIX standard defines a character class, which will be known by the regex processor installed. Those definitions are in the following table:\\n\n\n{| class=\"wikitable sortable\"\\n|-\\n! Description\\n! POSIX !! Perl/Tcl !! Vim !! Java !! ASCII\\n|-\\n| ASCII characters\\n|\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{ASCII}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[\\\\x00-\\\\x7F]</syntaxhighlight>\\n|-\\n| Alphanumeric characters\\n| <syntaxhighlight lang=\"ragel\" inline>[:alnum:]</syntaxhighlight>\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Alnum}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[A-Za-z0-9]</syntaxhighlight>\\n|-\\n| Alphanumeric characters plus \"_\"\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\w</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\w</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\w</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[A-Za-z0-9_]</syntaxhighlight>\\n|-\\n| Non-word characters\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\W</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\W</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\W</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[^A-Za-z0-9_]</syntaxhighlight>\\n|-\\n| Alphabetic characters\\n| <syntaxhighlight lang=\"ragel\" inline>[:alpha:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\a</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Alpha}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[A-Za-z]</syntaxhighlight>\\n|-\\n| Space and tab\\n| <syntaxhighlight lang=\"ragel\" inline>[:blank:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\s</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Blank}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[ \\\\t]</syntaxhighlight>\\n|-\\n| Word boundaries\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\b</syntaxhighlight>\\n| <code>\\\\&lt; \\\\&gt;</code>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\b</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>(?<=\\\\W)(?=\\\\w)|(?<=\\\\w)(?=\\\\W)</syntaxhighlight>\\n|-\\n| Non-word boundaries\\n|\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\B</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>(?<=\\\\W)(?=\\\\W)|(?<=\\\\w)(?=\\\\w)</syntaxhighlight>\\n|-\\n| [[Control character]]s\\n| <syntaxhighlight lang=\"ragel\" inline>[:cntrl:]</syntaxhighlight>\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Cntrl}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[\\\\x00-\\\\x1F\\\\x7F]</syntaxhighlight>\\n|-\\n| Digits\\n| <syntaxhighlight lang=\"ragel\" inline>[:digit:]</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\d</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\d</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Digit}</syntaxhighlight> or <syntaxhighlight lang=\"ragel\" inline>\\\\d</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[0-9]</syntaxhighlight>\\n|-\\n| Non-digits\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\D</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\D</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\D</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[^0-9]</syntaxhighlight>\\n|-\\n| Visible characters\\n| <syntaxhighlight lang=\"ragel\" inline>[:graph:]</syntaxhighlight>\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Graph}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[\\\\x21-\\\\x7E]</syntaxhighlight>\\n|-\\n| Lowercase letters\\n| <syntaxhighlight lang=\"ragel\" inline>[:lower:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\l</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Lower}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[a-z]</syntaxhighlight>\\n|-\\n| Visible characters and the space character\\n| <syntaxhighlight lang=\"ragel\" inline>[:print:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Print}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[\\\\x20-\\\\x7E]</syntaxhighlight>\\n|-\\n| Punctuation characters\\n| <syntaxhighlight lang=\"ragel\" inline>[:punct:]</syntaxhighlight>\\n|\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Punct}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[][!\"#$%&'()*+,./:;<=>?@\\\\^_`{|}~-]</syntaxhighlight>\\n|-\\n| [[Whitespace character]]s\\n| <syntaxhighlight lang=\"ragel\" inline>[:space:]</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\s</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\_s</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Space}</syntaxhighlight> or <syntaxhighlight lang=\"ragel\" inline>\\\\s</syntaxhighlight>\\n| <code>[ [[\\\\t]][[\\\\r]][[\\\\n]][[\\\\v]][[\\\\f]]]</code>\\n|-\\n| Non-whitespace characters\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\S</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\S</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\S</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[^ \\\\t\\\\r\\\\n\\\\v\\\\f]</syntaxhighlight>\\n|-\\n| Uppercase letters\\n| <syntaxhighlight lang=\"ragel\" inline>[:upper:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\u</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{Upper}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[A-Z]</syntaxhighlight>\\n|-\\n| Hexadecimal digits\\n| <syntaxhighlight lang=\"ragel\" inline>[:xdigit:]</syntaxhighlight>\\n|\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\x</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>\\\\p{XDigit}</syntaxhighlight>\\n| <syntaxhighlight lang=\"ragel\" inline>[A-Fa-f0-9]</syntaxhighlight>\\n|}\\n\n\nPOSIX character classes can only be used within bracket expressions. For example, <syntaxhighlight lang=\"ragel\" inline>[[:upper:]ab]</syntaxhighlight> matches the uppercase letters and lowercase \"a\" and \"b\".\\n\n\nAn additional non-POSIX class understood by some tools is <syntaxhighlight lang=\"ragel\" inline>[:word:]</syntaxhighlight>, which is usually defined as <syntaxhighlight lang=\"ragel\" inline>[:alnum:]</syntaxhighlight> plus underscore. This reflects the fact that in many programming languages these are the characters that may be used in identifiers. The editor [[Vim (text editor)|Vim]] further distinguishes ''word'' and ''word-head'' classes (using the notation <syntaxhighlight lang=\"ragel\" inline>\\\\w</syntaxhighlight> and <syntaxhighlight lang=\"ragel\" inline>\\\\h</syntaxhighlight>) since in many programming languages the characters that can begin an identifier are not the same as those that can occur in other positions: numbers are generally excluded, so an identifier would look like <syntaxhighlight lang=\"ragel\" inline>\\\\h\\\\w*</syntaxhighlight> or <syntaxhighlight lang=\"ragel\" inline>[[:alpha:]_][[:alnum:]_]*</syntaxhighlight> in POSIX notation.\\n\n\nNote that what the POSIX regex standards call ''character classes'' are commonly referred to as ''POSIX character classes'' in other regex flavors which support them. With most other regex flavors, the term ''character class'' is used to describe what POSIX calls ''bracket expressions''.\\n\n\n===Perl and PCRE===\\n{{See also|Perl Compatible Regular Expressions}}\\nBecause of its expressive power and (relative) ease of reading, many other utilities and programming languages have adopted syntax similar to [[Perl]]'s—for example, [[Java (programming language)|Java]], [[JavaScript]], [[Julia (programming language)|Julia]], [[Python (programming language)|Python]], [[Ruby (programming language)|Ruby]], [[Qt (software)|Qt]], Microsoft's [[.NET Framework]], and [[XML Schema (W3C)|XML Schema]]. Some languages and tools such as [[Boost C++ Libraries|Boost]] and [[PHP]] support multiple regex flavors. Perl-derivative regex implementations are not identical and usually implement a subset of features found in Perl 5.0, released in 1994. Perl sometimes does incorporate features initially found in other languages. For example, Perl 5.10 implements syntactic extensions originally developed in PCRE and Python.<ref>{{cite web | url=http://perldoc.perl.org/perlre.html#PCRE%2fPython-Support | title=Perl Regular Expression Documentation | publisher=perldoc.perl.org | access-date=January 8, 2012 | archive-date=December 31, 2009 | archive-url=https://web.archive.org/web/20091231010052/http://perldoc.perl.org/perlre.html#PCRE%2fPython-Support | url-status=live }}</ref>\\n\n\n===Lazy matching===\\nIn Python and some<!---should be 'many', or 'most', or 'a few', or ...?---> other implementations (e.g. Java), the three common quantifiers (<code>*</code>, <code>+</code> and <code>?</code>) are [[greedy algorithm|greedy]] by default because they match as many characters as possible.<ref name=py-re>{{cite web|title=Regular Expression Syntax|url=https://docs.python.org/3/library/re.html#regular-expression-syntax|website=Python 3.5.0 documentation|publisher=[[Python Software Foundation]]|access-date=10 October 2015|archive-date=18 July 2018|archive-url=https://web.archive.org/web/20180718132241/https://docs.python.org/3/library/re.html#regular-expression-syntax}}</ref> The regex <code>\".+\"</code> (including the double-quotes) applied to the string\\n\n\n \"Ganymede,\" he continued, \"is the largest moon in the Solar System.\"\\n\n\nmatches the entire line (because the entire line begins and ends with a double-quote) instead of matching only the first part, <code>\"Ganymede,\"</code>. The aforementioned quantifiers may, however, be made ''lazy'' or ''minimal'' or ''reluctant'', matching as few characters as possible, by appending a question mark: <code>\".+?\"</code> matches only <code>\"Ganymede,\"</code>.<ref name=\"py-re\" />\\n\n\n===Possessive matching===\\nIn Java and Python 3.11+,<ref>[https://github.com/python/cpython/issues/34627/  SRE: Atomic Grouping (?>...) is not supported #34627]</ref> quantifiers may be made ''possessive'' by appending a plus sign, which disables backing off (in a backtracking engine), even if doing so would allow the overall match to succeed:<ref name=es-re>{{cite web|title=Essential classes: Regular Expressions: Quantifiers: Differences Among Greedy, Reluctant, and Possessive Quantifiers|url=https://docs.oracle.com/javase/tutorial/essential/regex/quant.html#difs|website=The Java Tutorials|publisher=[[Oracle Corporation|Oracle]]|access-date=23 December 2016|archive-date=7 October 2020|archive-url=https://web.archive.org/web/20201007183203/https://docs.oracle.com/javase/tutorial/essential/regex/quant.html#difs|url-status=live}}</ref> While the regex <code>\".*\"</code> applied to the string\\n\n\n \"Ganymede,\" he continued, \"is the largest moon in the Solar System.\"\\n\n\nmatches the entire line, the regex <code>\".*+\"</code> does {{em|not match at all}}, because <code>.*+</code> consumes the entire input, including the final <code>\"</code>. Thus, possessive quantifiers are most useful with negated character classes, e.g. <code>\"[^\"]*+\"</code>, which matches <code>\"Ganymede,\"</code> when applied to the same string.\\n\n\nAnother common extension serving the same function is atomic grouping, which disables backtracking for a parenthesized group. The typical syntax is {{mono|1=(?&gt;group)}}. For example, while {{mono|1=^(wi{{!}}w)i$}} matches both {{mono|wi}} and {{mono|wii}}, {{mono|1=^(?&gt;wi{{!}}w)i$}} only matches {{mono|wii}} because the engine is forbidden from backtracking and so cannot try setting the group to \"w\" after matching \"wi\".<ref>{{cite web |title=Atomic Grouping |url=https://www.regular-expressions.info/atomic.html |website=Regex Tutorial |access-date=24 November 2019 |archive-date=7 October 2020 |archive-url=https://web.archive.org/web/20201007183204/https://www.regular-expressions.info/atomic.html |url-status=live }}</ref>\\n\n\nPossessive quantifiers are easier to implement than greedy and lazy quantifiers, and are typically more efficient at runtime.<ref name=es-re/>\\n\n\n==Patterns for non-regular languages==\\nMany features found in virtually all modern regular expression libraries provide an expressive power that exceeds the [[regular language]]s. For example, many implementations allow grouping subexpressions with parentheses and recalling the value they match in the same expression (''{{visible anchor|backreferences}}''). This means that, among other things, a pattern can match strings of repeated words like \"papa\" or \"WikiWiki\", called ''squares'' in formal language theory. The pattern for these strings is <code>(.+)\\\\1</code>.\\n\n\nThe language of squares is not regular, nor is it [[context-free language|context-free]], due to the [[Pumping lemma for context-free languages|pumping lemma]]. However, [[pattern matching]] with an unbounded number of backreferences, as supported by numerous modern tools, is still [[context-sensitive language|context sensitive]].<ref>{{cite journal | author=Cezar Câmpeanu | author2=Kai Salomaa | author3=Sheng Yu | name-list-style=amp | title=A Formal Study of Practical Regular Expressions | journal=International Journal of Foundations of Computer Science | volume=14 | number=6 | pages=1007–1018 | url=http://137.149.157.5/Articles/index.php?aid=1<!---This url was taken from Câmpeanu's publications page http://www.csit.upei.ca/~ccampeanu/Research/RJ---> | date=Dec 2003 | doi=10.1142/S012905410300214X | access-date=2015-07-03 | archive-date=2015-07-04 | archive-url=https://web.archive.org/web/20150704141706/http://137.149.157.5/Articles/index.php?aid=1 | url-status=live }} Theorem 3 (p.9)</ref> The general problem of matching any number of backreferences is [[NP-complete]], growing exponentially by the number of backref groups used.<ref>{{cite web |title=Perl Regular Expression Matching is NP-Hard |url=https://perl.plover.com/NPC/ |website=perl.plover.com |access-date=2019-11-21 |archive-date=2020-10-07 |archive-url=https://web.archive.org/web/20201007183205/https://perl.plover.com/NPC/ |url-status=live }}</ref>\\n\n\nHowever, many tools, libraries, and engines that provide such constructions still use the term ''regular expression'' for their patterns. This has led to a nomenclature where the term regular expression has different meanings in [[formal language|formal language theory]] and pattern matching. For this reason, some people have taken to using the term ''regex'', ''regexp'', or simply ''pattern'' to describe the latter. [[Larry Wall]], author of the Perl programming language, writes in an essay about the design of Raku:\\n\n\n{{Blockquote|1=\"Regular expressions\" […] are only marginally related to real regular expressions. Nevertheless, the term has grown with the capabilities of our pattern matching engines, so I'm not going to try to fight linguistic necessity here. I will, however, generally call them \"regexes\" (or \"regexen\", when I'm in an Anglo-Saxon mood).<ref name=\"Apocalypse5\" />}}\\n\n\n===Assertions===\\n\n\n{| id=\"lookbehind\" class=\"floatright wikitable\"\\n|-\\n! Assertion !! Lookbehind !! Lookahead\\n|-\\n! Positive\\n| style=\"text-align:center;font-size:125%;\"|<code>(?'''<='''{{box|inline=yes|span=yes|type=black|radius=1ex|padding=0 0.5ex|font size=80%|pattern}})</code>\\n| style=\"text-align:center;font-size:125%;\"|<code>(?'''='''{{box|inline=yes|span=yes|type=black|radius=1ex|padding=0 0.5ex|font size=80%|pattern}})</code>\\n|-\\n! Negative\\n| style=\"text-align:center;font-size:125%;\"|<code>(?'''&lt;!'''{{box|inline=yes|span=yes|type=black|radius=1ex|font size=80%|padding=0 0.5ex|pattern}})</code>\\n| style=\"text-align:center;font-size:125%;\"|<code>(?<span style=\"padding:1px;\">'''!'''</span>{{box|inline=yes|span=yes|type=black|radius=1ex|padding=0 0.5ex|font size=80%|pattern}})</code>\\n|-\\n| colspan=\"3\"|Look-behind and look-ahead assertions<br />in [[Perl]] regular expressions\\n|}\\nOther features not found in describing regular languages include assertions. These include the ubiquitous {{code|^}} and {{code|$}}, used since at least 1970,<ref>{{cite book |first1=D. M. |last1=Ritchie |first2=K. L. |last2=Thompson |title=QED Text Editor |url=https://wayback.archive-it.org/all/20150203071645/http://cm.bell-labs.com/cm/cs/who/dmr/qedman.pdf |id=MM-70-1373-3 |date=June 1970 }} Reprinted as \"QED Text Editor Reference Manual\", MHCC-004, Murray Hill Computing, Bell Laboratories (October 1972).</ref> as well as some more sophisticated extensions like lookaround that appeared in 1994.{{r|perl5}} Lookarounds define the surrounding of a match and don't spill into the match itself, a feature only relevant for the use case of string searching {{citation needed|date=June 2023}}. Some of them can be simulated in a regular language by treating the surroundings as a part of the language as well.<ref>{{cite web |author=Wandering Logic |title=How to simulate lookaheads and lookbehinds in finite state automata? |url=https://cs.stackexchange.com/a/40058 |website=Computer Science Stack Exchange |access-date=24 November 2019 |archive-date=7 October 2020 |archive-url=https://web.archive.org/web/20201007183206/https://cs.stackexchange.com/questions/2557/how-to-simulate-backreferences-lookaheads-and-lookbehinds-in-finite-state-auto/40058 |url-status=live }}</ref>\\n\n\nThe {{va|look-ahead assertions}} {{nowrap|1=<code>(?=...)</code>}} and {{nowrap|<code>(?!...)</code>}} have been attested since at least 1994, starting with Perl 5.<ref name=perl5>{{cite web |last=Wall |first=Larry |title=Perl 5: perlre.pod |url=https://github.com/Perl/perl5/blob/a0d0e21ea6ea90a22318550944fe6cb09ae10cda/pod/perlre.pod |date=1994-10-18 |website=GitHub}}</ref> The look-behind assertions {{nowrap|1=<code>(?<=...)</code>}} and {{nowrap|<code>(?<!...)</code>}} are attested since 1997 in a commit by Ilya Zakharevich to Perl 5.005.<ref>{{cite web |last=Zakharevich |first=Ilya |title=Jumbo Regexp Patch Applied (with Minor Fix-Up Tweaks): Perl/perl5@c277df4 |url=https://github.com/Perl/perl5/commit/c277df42229d99fecbc76f5da53793a409ac66e1 |website=GitHub |date=1997-11-19}}</ref><!-- I emailed Ilya Zakharevich to confirm, and he confirmed that he came up with the notation. -->\\n\n\n==Implementations and running times<span class=\"anchor\" id=\"Implementations\"></span>==\\nThere are at least three different [[algorithm]]s that decide whether and how a given regex matches a string.\\n\n\nThe oldest and fastest relies on a result in formal language theory that allows every [[nondeterministic finite automaton]] (NFA) to be transformed into a [[deterministic finite automaton]] (DFA). The DFA can be constructed explicitly and then run on the resulting input string one symbol at a time. Constructing the DFA for a regular expression of size ''m'' has the time and memory cost of [[Big O notation|''O'']](2<sup>''m''</sup>), but it can be run on a string of size ''n'' in time ''O''(''n'').  Note that the size of the expression is the size after abbreviations, such as numeric quantifiers, have been expanded.\\n\n\nAn alternative approach is to simulate the NFA directly, essentially building each DFA state on demand and then discarding it at the next step. This keeps the DFA implicit and avoids the exponential construction cost, but running cost rises to ''O''(''mn''). The explicit approach is called the DFA algorithm and the implicit approach the NFA algorithm. Adding caching to the NFA algorithm is often called the \"lazy DFA\" algorithm, or just the DFA algorithm without making a distinction. These algorithms are fast, but using them for recalling grouped subexpressions, lazy quantification, and similar features is tricky.<ref>{{harvtxt|Cox|2007}}</ref><ref>{{harvtxt|Laurikari|2009}}</ref> Modern implementations include the re1-re2-sregex family based on Cox's code.\\n\n\nThe third algorithm is to match the pattern against the input string by [[backtracking]]. This algorithm is commonly called NFA, but this terminology can be confusing. Its running time can be exponential, which simple implementations exhibit when matching against expressions like {{code|lang=perl|code=(a{{!}}aa)*b}} that contain both alternation and unbounded quantification and force the algorithm to consider an exponentially increasing number of sub-cases. This behavior can cause a security problem called [[Regular expression Denial of Service]] (ReDoS).\\n\n\nAlthough backtracking implementations only give an exponential guarantee in the worst case, they provide much greater flexibility and expressive power. For example, any implementation which allows the use of backreferences, or implements the various extensions introduced by Perl, must include some kind of backtracking. Some implementations try to provide the best of both algorithms by first running a fast DFA algorithm, and revert to a potentially slower backtracking algorithm only when a backreference is encountered during the match. GNU grep (and the underlying gnulib DFA) uses such a strategy.<ref>{{cite web |title=gnulib/lib/dfa.c |url=https://git.savannah.gnu.org/gitweb/?p=gnulib.git;a=blob;f=lib/dfa.c |quote=If the scanner detects a transition on backref, it returns a kind of \"semi-success\" indicating that the match will have to be verified with a backtracking matcher. |access-date=2022-02-12 |archive-date=2021-08-18 |archive-url=https://web.archive.org/web/20210818191338/https://git.savannah.gnu.org/gitweb/?p=gnulib.git%3Ba%3Dblob%3Bf%3Dlib%2Fdfa.c }}</ref>\\n\n\nSublinear runtime algorithms have been achieved using [[Boyer–Moore string-search algorithm|Boyer-Moore (BM) based algorithms]] and related DFA optimization techniques such as the reverse scan.<ref>{{cite arXiv |last=Kearns |first=Steven |eprint=1308.3822 |title=Sublinear Matching With Finite Automata Using Reverse Suffix Scanning |date=August 2013|class=cs.DS }}</ref> GNU grep, which supports a wide variety of POSIX syntaxes and extensions, uses BM for a first-pass prefiltering, and then uses an implicit DFA. Wu [[agrep]], which implements approximate matching, combines the prefiltering into the DFA in BDM (backward DAWG matching). NR-grep's BNDM extends the BDM technique with Shift-Or bit-level parallelism.<ref>{{cite journal |last1=Navarro |first1=Gonzalo |title=NR‐grep: a fast and flexible pattern‐matching tool |journal=Software: Practice and Experience |date=10 November 2001 |volume=31 |issue=13 |pages=1265–1312 |doi=10.1002/spe.411 |s2cid=3175806 |url=https://users.dcc.uchile.cl/~gnavarro/ps/spe01.pdf |access-date=21 November 2019 |archive-date=7 October 2020 |archive-url=https://web.archive.org/web/20201007183210/https://users.dcc.uchile.cl/~gnavarro/ps/spe01.pdf |url-status=live }}</ref>\\n\n\nA few theoretical alternatives to backtracking for backreferences exist, and their \"exponents\" are tamer in that they are only related to the number of backreferences, a fixed property of some regexp languages such as POSIX. One naive method that duplicates a non-backtracking NFA for each backreference note has a complexity of {{tmath|{\\\\mathrm O}(n^{2k+2})}} time and {{tmath|{\\\\mathrm O}(n^{2k+1})}} space for a haystack of length n and k backreferences in the RegExp.<ref>{{cite web |title=travisdowns/polyregex |website=[[GitHub]] |url=https://github.com/travisdowns/polyregex |date=5 July 2019 |access-date=21 November 2019 |archive-date=14 September 2020 |archive-url=https://web.archive.org/web/20200914170309/https://github.com/travisdowns/polyregex |url-status=live }}</ref> A very recent theoretical work based on memory automata gives a tighter bound based on \"active\" variable nodes used, and a polynomial possibility for some backreferenced regexps.<ref>{{cite arXiv |last=Schmid |first=Markus L. |eprint=1903.05896 |title=Regular Expressions with Backreferences: Polynomial-Time Matching Techniques |date=March 2019|class=cs.FL }}</ref>\\n\n\n==Unicode==\\nIn theoretical terms, any token set can be matched by regular expressions as long as it is pre-defined. In terms of historical implementations, regexes were originally written to use [[American Standard Code for Information Interchange|ASCII]] characters as their token set though regex libraries have supported numerous other [[character set]]s. Many modern regex engines offer at least some support for [[Unicode]]. In most respects it makes no difference what the character set is, but some issues do arise when extending regexes to support Unicode.\\n* '''Supported encoding'''. Some regex libraries expect to work on some particular encoding instead of on abstract Unicode characters. Many of these require the [[UTF-8]] encoding, while others might expect [[UTF-16]], or [[UTF-32]]. In contrast, Perl and Java are agnostic on encodings, instead operating on decoded characters internally.\\n* '''Supported Unicode range'''. Many regex engines support only the [[Basic Multilingual Plane]], that is, the characters which can be encoded with only 16 bits. Currently (as of {{As of|2016|bare=yes}}) only a few regex engines (e.g., Perl's and Java's) can handle the full 21-bit Unicode range.\\n* '''Extending ASCII-oriented constructs to Unicode'''. For example, in ASCII-based implementations, character ranges of the form <code>[x-y]</code> are valid wherever ''x'' and ''y'' have [[code point]]s in the range [0x00,0x7F] and codepoint(''x'') ≤ codepoint(''y''). The natural extension of such character ranges to Unicode would simply change the requirement that the endpoints lie in [0x00,0x7F] to the requirement that they lie in [0x0000,0x10FFFF]. However, in practice this is often not the case. Some implementations, such as that of [[Gawk (GNU package)|gawk]], do not allow character ranges to cross Unicode blocks. A range like [0x61,0x7F] is valid since both endpoints fall within the Basic Latin block, as is [0x0530,0x0560] since both endpoints fall within the Armenian block, but a range like [0x0061,0x0532] is invalid since it includes multiple Unicode blocks. Other engines, such as that of the [[Vim (text editor)|Vim]] editor, allow block-crossing but the character values must not be more than 256 apart.<ref>{{cite web |url=http://vimdoc.sourceforge.net/htmldoc/pattern.html#/%5B%5D |title=Vim documentation: pattern |publisher=Vimdoc.sourceforge.net |access-date=2013-09-25 |archive-date=2020-10-07 |archive-url=https://web.archive.org/web/20201007183210/http://vimdoc.sourceforge.net/htmldoc/pattern.html#/%5B%5D |url-status=live }}</ref>\\n* '''Case insensitivity'''. Some case-insensitivity flags affect only the ASCII characters. Other flags affect all characters. Some engines have two different flags, one for ASCII, the other for Unicode. Exactly which characters belong to the POSIX classes also varies.\\n* '''Cousins of case insensitivity'''. As ASCII has case distinction, case insensitivity became a logical feature in text searching. Unicode introduced alphabetic scripts without case like [[Devanāgarī|Devanagari]]. For these, [[case sensitivity]] is not applicable. For scripts like Chinese, another distinction seems logical: between traditional and simplified. In Arabic scripts, insensitivity to [[IMFI|initial, medial, final, and isolated position]] may be desired. In Japanese, insensitivity between [[hiragana]] and [[katakana]] is sometimes useful.\\n* '''Normalization'''. Unicode has [[Unicode#Combining characters|combining characters]]. Like old typewriters, plain base characters (white spaces, punctuation characters, symbols, digits, or letters) can be followed by one or more non-spacing symbols (usually diacritics, like accent marks modifying letters) to form a single printable character; but Unicode also provides a limited set of precomposed characters, i.e. characters that already include one or more combining characters. A sequence of a base character + combining characters should be matched with the identical single precomposed character (only some of these combining sequences can be precomposed into a single Unicode character, but infinitely many other combining sequences are possible in Unicode, and needed for various languages, using one or more combining characters after an initial base character; these combining sequences ''may'' include a base character or combining characters partially precomposed, but not necessarily in canonical order and not necessarily using the canonical precompositions). The process of standardizing sequences of a base character + combining characters by decomposing these ''canonically equivalent'' sequences, before reordering them into canonical order (and optionally recomposing ''some'' combining characters into the leading base character) is called normalization.\\n* '''New control codes'''. Unicode introduced amongst others, [[byte order mark]]s and text direction markers. These codes might have to be dealt with in a special way.\\n* '''Introduction of character classes for Unicode blocks, scripts, and numerous other character properties'''. Block properties are much less useful than script properties, because a block can have code points from several different scripts, and a script can have code points from several different blocks.<ref name=\"unicode\">{{cite web\\n| title = UTS#18 on Unicode Regular Expressions, Annex A: Character Blocks\\n| url = http://unicode.org/reports/tr18/#Character_Blocks\\n| access-date = 2010-02-05\\n| archive-date = 2020-10-07\\n| archive-url = https://web.archive.org/web/20201007183210/http://unicode.org/reports/tr18/#Character_Blocks\\n| url-status = live\\n}}</ref> In [[Perl]] and the {{Javadoc:SE|package=java.util.regex|java/util/regex}} library, properties of the form <code>\\\\p{InX}</code> or <code>\\\\p{Block=X}</code> match characters in block ''X'' and <code>\\\\P{InX}</code> or <code>\\\\P{Block=X}</code> matches code points not in that block. Similarly, <code>\\\\p{Armenian}</code>, <code>\\\\p{IsArmenian}</code>, or <code>\\\\p{Script=Armenian}</code> matches any character in the Armenian script. In general, <code>\\\\p{X}</code> matches any character with either the binary property ''X'' or the general category ''X''. For example, <code>\\\\p{Lu}</code>, <code>\\\\p{Uppercase_Letter}</code>, or <code>\\\\p{GC=Lu}</code> matches any uppercase letter. Binary properties that are ''not'' general categories include <code>\\\\p{White_Space}</code>, <code>\\\\p{Alphabetic}</code>, <code>\\\\p{Math}</code>, and <code>\\\\p{Dash}</code>. Examples of non-binary properties are <code>\\\\p{Bidi_Class=Right_to_Left}</code>, <code>\\\\p{Word_Break=A_Letter}</code>, and <code>\\\\p{Numeric_Value=10}</code>.\\n\n\n== Language support ==\\nMost [[general-purpose programming language]]s support regex capabilities, either natively or via [[Library (computing)|libraries]]. Comprehensive support is included in:\\n{{columns-list|colwidth=20em|\\n* [[C (programming language)|C]]<ref>{{Cite web |title=regex(3) - Linux manual page |url=https://man7.org/linux/man-pages/man3/regcomp.3.html |access-date=2022-04-27 |website=man7.org}}</ref>\\n* [[C++]]<ref>{{Cite web |title=Regular expressions library - cppreference.com |url=https://en.cppreference.com/w/cpp/regex |access-date=2022-04-27 |website=en.cppreference.com}}</ref>\\n* [[Java (programming language)|Java]]<ref>{{Cite web |title=Pattern (Java Platform SE 7 ) |url=https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html |access-date=2022-04-27 |website=docs.oracle.com}}</ref>\\n* [[JavaScript]]<ref>{{cite web |title=Regular expressions - JavaScript {{!}} MDN |url=https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_Expressions |access-date=2022-04-27 |website=developer.mozilla.org }}</ref>\\n* [[OCaml]]<ref>{{Cite web |title=OCaml library: Str |url=https://v2.ocaml.org/api/Str.html |access-date=2022-08-21 |website=v2.ocaml.org}}</ref>\\n* [[Perl]]<ref>{{Cite web |title=perlre |url=https://perldoc.perl.org/perlre |access-date=2023-02-04 |website=perldoc.perl.org}}</ref>\\n* [[PHP]]<ref>{{Cite web |title=PHP: PCRE - Manual |url=https://www.php.net/manual/en/book.pcre.php |access-date=2023-02-04 |website=www.php.net}}</ref>\\n* [[Python (programming language)|Python]]<ref>{{cite web |title=re – Regular expression operations |url=https://docs.python.org/3/library/re.html |website=docs.python.org |access-date=2023-02-24 }}</ref>\\n* [[Rust (programming language)|Rust]]<ref>{{cite web |title=Regex on crates.io |url=https://crates.io/crates/regex |url-status=live |website=Crates.io |archive-url=https://web.archive.org/web/20221129000056/https://crates.io/crates/regex |archive-date=2022-11-29 |access-date=2023-02-24 }}</ref>\\n}}\\n\n\n==Uses==\\n[[File:Screenshot of MediaWiki Blacklist.png|thumb|[[MediaWiki:Titleblacklist|A blacklist]] on [[Wikipedia]] which uses regular expressions to identify bad titles]]\\n\n\nRegexes are useful in a wide variety of text processing tasks, and more generally [[string processing]], where the data need not be textual. Common applications include [[data validation]], [[data scraping]] (especially [[web scraping]]), [[data wrangling]], simple [[parsing]], the production of [[syntax highlighting]] systems, and many other tasks.\\n\n\nWhile regexes would be useful on Internet [[Search engine (computing)|search engines]], processing them across the entire database could consume excessive computer resources depending on the complexity and design of the regex. Although in many cases system administrators can run regex-based queries internally, most search engines do not offer regex support to the public. Notable exceptions include [[Google Code Search]] and [[Exalead]]. However, Google Code Search was shut down in January 2012.<ref>{{cite web |first=Bradley |last=Horowitz |author-link=Bradley Horowitz |url=https://googleblog.blogspot.com/2011/10/fall-sweep.html |title=A fall sweep |date=24 October 2011 |access-date=4 May 2019 |work=[[Google Blog]] |archive-date=21 October 2018 |archive-url=https://web.archive.org/web/20181021074737/https://googleblog.blogspot.com/2011/10/fall-sweep.html |url-status=live }}</ref>\\n\n\n==Examples==\\nThe specific syntax rules vary depending on the specific implementation, [[programming language]], or [[Library (computing)|library]] in use. Additionally, the functionality of regex implementations can vary between [[Software versioning|versions]].\\n\n\nBecause regexes can be difficult to both explain and understand without examples, interactive websites for testing regexes are a useful resource for learning regexes by experimentation.\\nThis section provides a basic description of some of the properties of regexes by way of illustration.\\n\n\nThe following conventions are used in the examples.<ref name=\"clarify000\">The character 'm' is not always required to specify a [[Perl]] match operation. For example, <code>m/[^abc]/</code> could also be rendered as <code>/[^abc]/</code>. The 'm' is only necessary if the user wishes to specify a match operation without using a forward-slash as the regex [[delimiter]]. Sometimes it is useful to specify an alternate regex delimiter in order to avoid \"[[delimiter collision]]\". See '[http://perldoc.perl.org/perlre.html perldoc perlre] {{Webarchive|url=https://web.archive.org/web/20091231010052/http://perldoc.perl.org/perlre.html |date=2009-12-31 }}' for more details.</ref>\\n\n\n metacharacter(s) ;; the metacharacters column specifies the regex syntax being demonstrated\\n =~ m//           ;; indicates a regex ''match'' operation in Perl\\n =~ s///          ;; indicates a regex ''substitution'' operation in Perl\\n\n\nAlso worth noting is that these regexes are all Perl-like syntax. Standard [[#POSIX Basic Regular Expressions|POSIX]] regular expressions are different.\\n\n\nUnless otherwise indicated, the following examples conform to the [[Perl]] programming language, release 5.8.8, January 31, 2006. This means that other implementations may lack support for some parts of the syntax shown here (e.g. basic vs. extended regex, <code>\\\\( \\\\)</code> vs. <code>()</code>, or lack of <code>\\\\d</code> instead of [[POSIX]] <code>[:digit:]</code>).\\n\n\nThe syntax and conventions used in these examples coincide with that of other programming environments as well.<ref>E.g., see ''[[Java (programming language)|Java]] [[O'Reilly Media#In a Nutshell|in a Nutshell]]'', p. 213; ''[[Python (programming language)|Python]] Scripting for Computational Science'', p. 320; Programming [[PHP]], p. 106.</ref>\\n\n\n{| class=\"wikitable\"\\n|-\\n! Meta&shy;character(s)\\n! Description\\n! Example<ref>Note that all the if statements return a TRUE value</ref>\\n|-\\n! <code>.</code>\\n| Normally matches any character except a newline. <br />Within square brackets the dot is literal.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/...../) {\\n  print \"$string1 has length >= 5.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n has length >= 5.\\n</syntaxhighlight>\\n|-\\n! <code>( )</code>\\n| Groups a series of pattern elements to a single element. <br />When you match a pattern within parentheses, you can use any of <code>$1</code>, <code>$2</code>, ... later to refer to the previously matched pattern. Some implementations may use a backslash notation instead, like <code>\\\\1</code>, <code>\\\\2</code>.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/(H..).(o..)/) {\\n  print \"We matched '$1' and '$2'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nWe matched 'Hel' and 'o W'.\\n</syntaxhighlight>\\n|-\\n! <code>+</code>\\n| Matches the preceding pattern element one or more times.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/l+/) {\\n  print \"There are one or more consecutive letter \\\\\"l\\\\\"'s in $string1.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere are one or more consecutive letter \"l\"'s in Hello World.\\n</syntaxhighlight>\\n|-\\n! <code>?</code>\\n| Matches the preceding pattern element zero or one time.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/H.?e/) {\\n  print \"There is an 'H' and a 'e' separated by \";\\n  print \"0-1 characters (e.g., He Hue Hee).\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere is an 'H' and a 'e' separated by 0-1 characters (e.g., He Hue Hee).\\n</syntaxhighlight>\\n|-\\n! <code>?</code>\\n| Modifies the <code>*</code>, <code>+</code>, <code>?</code> or <code>{M,N}</code>'d regex that comes before to match as few times as possible.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/(l.+?o)/) {\\n  print \"The non-greedy match with 'l' followed by one or \";\\n  print \"more characters is 'llo' rather than 'llo Wo'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThe non-greedy match with 'l' followed by one or more characters is 'llo' rather than 'llo Wo'.\\n</syntaxhighlight>\\n|-\\n! <code>*</code>\\n| Matches the preceding pattern element zero or more times.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/el*o/) {\\n  print \"There is an 'e' followed by zero to many \";\\n  print \"'l' followed by 'o' (e.g., eo, elo, ello, elllo).\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere is an 'e' followed by zero to many 'l' followed by 'o' (e.g., eo, elo, ello, elllo).\\n</syntaxhighlight>\\n|-\\n! <code>{M,N}</code>\\n| Denotes the minimum M and the maximum N match count.<br />N can be omitted and M can be 0: <code>{M}</code> matches \"exactly\" M times; <code>{M,}</code> matches \"at least\" M times; <code>{0,N}</code> matches \"at most\" N times.<br /><code>x* y+ z?</code> is thus equivalent to <code>x{0,} y{1,} z{0,1}</code>.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/l{1,2}/) {\\n  print \"There exists a substring with at least 1 \";\\n  print \"and at most 2 l's in $string1\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere exists a substring with at least 1 and at most 2 l's in Hello World\\n</syntaxhighlight>\\n|-\\n! <code>[…]</code>\\n| Denotes a set of possible character matches.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/[aeiou]+/) {\\n  print \"$string1 contains one or more vowels.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n contains one or more vowels.\\n</syntaxhighlight>\\n|-\\n! <code><nowiki>|</nowiki></code>\\n| Separates alternate possibilities.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/(Hello|Hi|Pogo)/) {\\n  print \"$string1 contains at least one of Hello, Hi, or Pogo.\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n contains at least one of Hello, Hi, or Pogo.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\b</code>\\n| Matches a zero-width boundary between a word-class character (see next) and either a non-word class character or an edge; same as\\n<code>(^\\\\w|\\\\w$|\\\\W\\\\w|\\\\w\\\\W)</code>.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/llo\\\\b/) {\\n  print \"There is a word that ends with 'llo'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere is a word that ends with 'llo'.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\w</code>\\n| Matches an alphanumeric character, including \"_\"; <br />same as <code>[A-Za-z0-9_]</code> in ASCII, and\\n: <code>[\\\\p{Alphabetic}<wbr/>\\\\p{GC=Mark}<wbr/>\\\\p{GC=Decimal_Number}<wbr/>\\\\p{GC=Connector_Punctuation}]</code>\\nin Unicode,<ref name=\"unicode\" /> where the <code>Alphabetic</code> property contains more than Latin letters, and the <code>Decimal_Number</code> property contains more than Arab digits.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/\\\\w/) {\\n  print \"There is at least one alphanumeric \";\\n  print \"character in $string1 (A-Z, a-z, 0-9, _).\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere is at least one alphanumeric character in Hello World\\n (A-Z, a-z, 0-9, _).\\n</syntaxhighlight>\\n|-\\n! <code>\\\\W</code>\\n| Matches a ''non''-alphanumeric character, excluding \"_\"; <br />same as <code>[^A-Za-z0-9_]</code> in ASCII, and\\n:<code>[^\\\\p{Alphabetic}<wbr/>\\\\p{GC=Mark}<wbr/>\\\\p{GC=Decimal_Number}<wbr/>\\\\p{GC=Connector_Punctuation}]</code>\\nin Unicode.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/\\\\W/) {\\n  print \"The space between Hello and \";\\n  print \"World is not alphanumeric.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThe space between Hello and World is not alphanumeric.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\s</code>\\n| Matches a whitespace character, <br />which in ASCII are tab, line feed, form feed, carriage return, and space; <br />in Unicode, also matches no-<wbr/>break spaces, next line, and the variable-<wbr/>width spaces (amongst others).\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/\\\\s.*\\\\s/) {\\n  print \"In $string1 there are TWO whitespace characters, which may\";\\n  print \" be separated by other characters.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nIn Hello World\\n there are TWO whitespace characters, which may be separated by other characters.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\S</code>\\n| Matches anything ''but'' a whitespace.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/\\\\S.*\\\\S/) {\\n  print \"In $string1 there are TWO non-whitespace characters, which\";\\n  print \" may be separated by other characters.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nIn Hello World\\n there are TWO non-whitespace characters, which may be separated by other characters.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\d</code>\\n| Matches a digit; <br />same as <code>[0-9]</code> in ASCII; <br />in Unicode, same as the <code>\\\\p{Digit}</code> or <code>\\\\p{GC=Decimal_Number}</code> property, which itself the same as the <code>\\\\p{Numeric_Type=Decimal}</code> property.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"99 bottles of beer on the wall.\";\\nif ($string1 =~ m/(\\\\d+)/) {\\n  print \"$1 is the first number in '$string1'\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\n99 is the first number in '99 bottles of beer on the wall.'\\n</syntaxhighlight>\\n|-\\n! <code>\\\\D</code>\\n| Matches a non-digit; <br />same as <code>[^0-9]</code> in ASCII or <code>\\\\P{Digit}</code> in Unicode.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/\\\\D/) {\\n  print \"There is at least one character in $string1\";\\n  print \" that is not a digit.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nThere is at least one character in Hello World\\n that is not a digit.\\n</syntaxhighlight>\\n|-\\n! <code>^</code>\\n| Matches the beginning of a line or string.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/^He/) {\\n  print \"$string1 starts with the characters 'He'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n starts with the characters 'He'.\\n</syntaxhighlight>\\n|-\\n! <code>$</code>\\n| Matches the end of a line or string.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/rld$/) {\\n  print \"$string1 is a line or string \";\\n  print \"that ends with 'rld'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n is a line or string that ends with 'rld'.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\A</code>\\n| Matches the beginning of a string (but not an internal line).\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello\\\\nWorld\\\\n\";\\nif ($string1 =~ m/\\\\AH/) {\\n  print \"$string1 is a string \";\\n  print \"that starts with 'H'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello\\nWorld\\n is a string that starts with 'H'.\\n</syntaxhighlight>\\n|-\\n! <code>\\\\z</code>\\n| Matches the end of a string (but not an internal line).<ref name=\"Perl Best Practices\">{{cite book | last = Conway | first = Damian | author-link = Damian Conway | title = Perl Best Practices | chapter = Regular Expressions, End of String | publisher = [[O'Reilly Media|O'Reilly]] | page = 240 | chapter-url = https://www.scribd.com/doc/15491004/Perl-Best-Practices | year = 2005 | isbn = 978-0-596-00173-5 | access-date = 2017-09-10 | archive-date = 2020-10-07 | archive-url = https://web.archive.org/web/20201007183212/https://www.scribd.com/book/15491004/Perl-Best-Practices-Standards-and-Styles-for-Developing-Maintainable-Code | url-status = live }}</ref>\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello\\\\nWorld\\\\n\";\\nif ($string1 =~ m/d\\\\n\\\\z/) {\\n  print \"$string1 is a string \";\\n  print \"that ends with 'd\\\\\\\\n'.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello\\nWorld\\n is a string that ends with 'd\\\\n'.\\n</syntaxhighlight>\\n|-\\n! <code>[^…]</code>\\n| Matches every character except the ones inside brackets.\\n| <syntaxhighlight lang=\"perl\">\\n$string1 = \"Hello World\\\\n\";\\nif ($string1 =~ m/[^abc]/) {\\n print \"$string1 contains a character other than \";\\n print \"a, b, and c.\\\\n\";\\n}\\n</syntaxhighlight>\\n'''Output:'''\\n<syntaxhighlight lang=\"output\">\\nHello World\\n contains a character other than a, b, and c.\\n</syntaxhighlight>\\n|}\\n\n\n==Induction==\\n{{Main|Induction of regular languages}}\\n\n\nRegular expressions can often be created (\"induced\" or \"learned\") based on a set of example strings. This is known as the [[induction of regular languages]] and is part of the general problem of [[grammar induction]] in [[computational learning theory]]. Formally, given examples of strings in a regular language, and perhaps also given examples of strings ''not'' in that regular language, it is possible to induce a grammar for the language, i.e., a regular expression that generates that language. Not all regular languages can be induced in this way (see [[language identification in the limit]]), but many can. For example, the set of examples {1, 10, 100}, and negative set (of counterexamples) {11, 1001, 101, 0} can be used to induce the regular expression 1⋅0* (1 followed by zero or more 0s).\\n\n\n==See also==\\n* [[Comparison of regular expression engines]]\\n* [[Extended Backus–Naur form]]\\n* [[Matching wildcards]]\\n* [[Regular tree grammar]]\\n* [[Thompson's construction]] – converts a regular expression into an equivalent [[nondeterministic finite automaton|nondeterministic finite automaton (NFA)]]\\n\n\n==Notes==\\n{{Reflist}}\\n\n\n==References==\\n{{Refbegin|30em}}\\n* {{cite book\\n | last = Aho\\n | first = Alfred V.\\n | author-link =Alfred Aho\\n | year = 1990\\n | title = Algorithms for finding patterns in strings\\n | editor-last = van Leeuwen\\n | editor-first = Jan | editor-link = Jan van Leeuwen\\n | work = Handbook of Theoretical Computer Science, volume A: Algorithms and Complexity\\n | publisher = The MIT Press\\n | pages = 255–300\\n }}\\n* {{cite book\\n | last1 = Aho\\n | first1 = Alfred V.\\n | last2 = Ullman\\n | first2 = Jeffrey D.\\n | author-link2 = Jeffrey Ullman\\n | year = 1992\\n | title = Foundations of Computer Science\\n | url = http://infolab.stanford.edu/~ullman/focs.html\\n | chapter = Chapter 10. Patterns, Automata, and Regular Expressions\\n | chapter-url = http://infolab.stanford.edu/~ullman/focs/ch10.pdf\\n | access-date = 2013-12-14\\n | archive-date = 2020-10-07\\n | archive-url = https://web.archive.org/web/20201007183211/http://infolab.stanford.edu/~ullman/focs.html\\n | url-status = live\\n }}\\n* {{Cite journal |last=Aycock |first=John |title=A brief history of just-in-time |doi=10.1145/857076.857077 | journal=ACM Computing Surveys |volume=35 |issue=2 |pages=97–113 |date=June 2003 |citeseerx=10.1.1.97.3985 |s2cid=15345671 |url=https://www.cs.tufts.edu/comp/150CMP/papers/aycock03jit.pdf}}\\n* {{cite book\\n | publisher = The Open Group\\n | url = http://pubs.opengroup.org/onlinepubs/007908799/xbd/re.html\\n | section= Regular Expressions\\n | title= The Single UNIX Specification, Version 2\\n | year = 1997\\n | access-date = 2011-12-13\\n | archive-date = 2020-10-07\\n | archive-url = https://web.archive.org/web/20201007183212/https://pubs.opengroup.org/onlinepubs/007908799/xbd/re.html\\n | url-status = live\\n }}\\n* {{cite journal\\n | publisher = The Open Group\\n | url = http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html\\n | title = Chapter 9: Regular Expressions\\n | journal = The Open Group Base Specifications\\n | issue = 6\\n | id = IEEE Std 1003.1, 2004 Edition\\n | year = 2004\\n | access-date = 2011-12-13\\n | archive-date = 2011-12-02\\n | archive-url = https://web.archive.org/web/20111202145637/http://pubs.opengroup.org/onlinepubs/009695399/basedefs/xbd_chap09.html\\n | url-status = live\\n }}\\n* {{cite web\\n | url = http://swtch.com/~rsc/regexp/regexp1.html\\n | title = Regular Expression Matching Can Be Simple and Fast\\n | last = Cox\\n | first = Russ\\n | year = 2007\\n | access-date = 2008-04-27\\n | archive-date = 2010-01-01\\n | archive-url = https://web.archive.org/web/20100101190447/http://swtch.com/~rsc/regexp/regexp1.html\\n }}\\n* {{cite book\\n | first = Ben\\n | last = Forta\\n | author-link = Ben Forta\\n | year =2004\\n | title = Sams Teach Yourself Regular Expressions in 10 Minutes\\n | publisher = Sams\\n | isbn = 978-0-672-32566-3\\n}}\\n* {{cite book\\n | first = Jeffrey E. F.\\n | last = Friedl\\n | year = 2002\\n | title = Mastering Regular Expressions\\n | url = http://regex.info/\\n | publisher = [[O'Reilly Media|O'Reilly]]\\n | isbn = 978-0-596-00289-3\\n | access-date = 2005-04-26\\n | archive-date = 2005-08-30\\n | archive-url = https://web.archive.org/web/20050830113350/http://regex.info/\\n | url-status = live\\n }}\\n* {{cite conference\\n | last1 = Gelade\\n | first1 = Wouter\\n | last2 = Neven\\n | first2 = Frank\\n | title = Succinctness of the Complement and Intersection of Regular Expressions\\n | pages = 325–336\\n | work = Proceedings of the 25th International Symposium on Theoretical Aspects of Computer Science (STACS 2008)\\n | url = http://drops.dagstuhl.de/opus/volltexte/2008/1354\\n | year = 2008\\n | arxiv = 0802.2869\\n | access-date = 2009-06-15\\n | archive-date = 2011-07-18\\n | archive-url = https://web.archive.org/web/20110718225605/http://drops.dagstuhl.de/opus/volltexte/2008/1354/\\n }}\\n* {{cite book\\n | first1 = Jan\\n | last1 = Goyvaerts\\n | first2=Steven |last2=Levithan\\n | year =2009\\n | title = Regular Expressions Cookbook\\n | publisher = [O'reilly]\\n | isbn = 978-0-596-52068-7\\n}}\\n* {{cite conference\\n | last1 = Gruber\\n | first1 = Hermann\\n | last2 = Holzer\\n | first2 = Markus\\n | title = Finite Automata, Digraph Connectivity, and Regular Expression Size\\n | pages = 39–50\\n | work = Proceedings of the 35th International Colloquium on Automata, Languages and Programming (ICALP 2008)\\n | series = Lecture Notes in Computer Science\\n | url = http://www.hermann-gruber.com/data/icalp08.pdf\\n | year = 2008\\n | doi = 10.1007/978-3-540-70583-3_4\\n | volume = 5126\\n | isbn = 978-3-540-70582-6\\n | access-date = 2011-02-03\\n | archive-date = 2011-07-11\\n | archive-url = https://web.archive.org/web/20110711163607/http://www.hermann-gruber.com/data/icalp08.pdf\\n | url-status = live\\n }}\\n* {{cite book\\n | first = Mehran\\n | last = Habibi\\n | year =2004\\n | title = Real World Regular Expressions with Java 1.4\\n | publisher = Springer\\n | isbn = 978-1-59059-107-9\\n}}\\n* {{cite book\\n | last1 = Hopcroft\\n | first1 = John E.\\n | last2 = Motwani\\n | first2 = Rajeev\\n | last3 = Ullman\\n | first3 = Jeffrey D.\\n | title = Introduction to Automata Theory, Languages, and Computation\\n | publisher = Addison-Wesley\\n | year = 2000\\n | edition = 2nd\\n }}\\n* {{Cite journal |last1=Johnson |first1=Walter L. |last2=Porter |first2=James H. |last3=Ackley |first3=Stephanie I. |last4=Ross |first4=Douglas T. |title=Automatic generation of efficient lexical processors using finite state techniques |doi=10.1145/364175.364185 |journal=Communications of the ACM |volume=11 |issue=12 |pages=805–813 |date=1968 |s2cid=17253809 }}\\n* {{cite book\\n |last = Kleene\\n |first = Stephen C.\\n |title = Representation of Events in Nerve Nets and Finite Automata\\n |work = Automata Studies\\n |editor1-last = Shannon\\n |editor1-first = Claude E.\\n |editor2-last = McCarthy\\n |editor2-first = John\\n |url = https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM704.pdf\\n |publisher = Princeton University Press\\n |year = 1951\\n |pages = 3–42\\n |access-date = 2017-12-10\\n |archive-date = 2020-10-07\\n |archive-url = https://web.archive.org/web/20201007183213/https://www.rand.org/content/dam/rand/pubs/research_memoranda/2008/RM704.pdf\\n |url-status = live\\n }}\\n* {{cite book\\n |last = Kozen\\n |first = Dexter\\n |chapter = A completeness theorem for Kleene algebras and the algebra of regular events\\n |title = &#91;1991&#93; Proceedings Sixth Annual IEEE Symposium on Logic in Computer Science\\n |pages = 214–225\\n |year = 1991\\n |hdl = 1813/6963\\n |doi = 10.1109/LICS.1991.151646\\n |isbn = 978-0-8186-2230-4\\n |s2cid = 19875225\\n }}\\n* {{cite web\\n | url = http://www.laurikari.net/tre/\\n | title = TRE library 0.7.6\\n | first = Ville\\n | last = Laurikari\\n | year = 2009\\n | access-date = 2009-04-01\\n | archive-date = 2010-07-14\\n | archive-url = https://web.archive.org/web/20100714224701/http://laurikari.net/tre/\\n }}\\n* {{cite book\\n | first1 = François\\n | last1 = Liger\\n |first2=Craig |last2=McQueen |first3=Paul |last3=Wilton\\n | year =2002\\n | title = Visual Basic .NET Text Manipulation Handbook\\n | publisher = [[Wrox Press]]\\n | isbn = 978-1-86100-730-8\\n}}\\n* {{cite book\\n | first = Michael\\n | last = Sipser\\n | author-link = Michael Sipser\\n | year = 1998\\n | title = Introduction to the Theory of Computation\\n | chapter = Chapter 1: Regular Languages\\n | pages = [https://archive.org/details/introductiontoth00sips/page/31 31–90]\\n | publisher = PWS Publishing\\n | isbn = 978-0-534-94728-6\\n | chapter-url-access = registration\\n | chapter-url = https://archive.org/details/introductiontoth00sips/page/31\\n }}\\n* {{cite book\\n | first = Tony\\n | last = Stubblebine\\n | year =2003\\n | title = Regular Expression Pocket Reference\\n | publisher = O'Reilly\\n | isbn = 978-0-596-00415-6\\n}}\\n* {{Cite journal | last = Thompson | first = Ken | author-link = Ken Thompson | title = Programming Techniques: Regular expression search algorithm | doi = 10.1145/363347.363387 | journal = Communications of the ACM | volume = 11 | issue = 6 | pages = 419–422 | year = 1968 | s2cid = 21260384 | doi-access = free }}\\n* {{cite web\\n | url=http://dev.perl.org/perl6/doc/design/apo/A05.html\\n | title=Apocalypse 5: Pattern Matching\\n | first=Larry\\n | last=Wall\\n | author-link=Larry Wall\\n | date=2002\\n | access-date=2006-10-11\\n | archive-date=2010-01-12\\n | archive-url=https://web.archive.org/web/20100112232513/http://dev.perl.org/perl6/doc/design/apo/A05.html\\n | url-status=live\\n }}\\n{{Refend}}\\n\n\n==External links==\\n<!-- Please note: There are thousands of regex tools in existence. Since Wikipedia is not a repository of links (see [[WP:NOT]] and [[WP:LINKS]]), please do not add links to such resources. They will likely be removed. -->\\n{{Wikibooks|Regular Expressions}}\\n{{Wikibooks\\n|1=R Programming\\n|2=Text Processing\\n}}\\n{{Wiktionary|regular expression}}\\n* {{Commons category-inline|Regex}}\\n* {{curlie|Computers/Programming/Languages/Regular_Expressions|Regular Expressions}}\\n* ISO/IEC 9945-2:1993 [http://www.iso.org/iso/catalogue_detail.htm?csnumber=17841 ''Information technology – Portable Operating System Interface (POSIX) – Part 2: Shell and Utilities'']\\n* ISO/IEC 9945-2:2002 [http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=37313 ''Information technology – Portable Operating System Interface (POSIX) – Part 2: System Interfaces'']\\n* ISO/IEC 9945-2:2003 [http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=38790 ''Information technology – Portable Operating System Interface (POSIX) – Part 2: System Interfaces'']\\n* ISO/IEC/IEEE 9945:2009 [http://www.iso.org/iso/iso_catalogue/catalogue_ics/catalogue_detail_ics.htm?csnumber=50516 ''Information technology – Portable Operating System Interface (POSIX) Base Specifications, Issue 7'']\\n* [http://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap09.html Regular Expression, IEEE Std 1003.1-2017, Open Group]\\n\n\n{{Formal languages and grammars}}\\n{{Strings}}\\n{{Authority control}}\\n\n\n[[Category:Regular expressions| ]]\\n[[Category:1951 introductions]]\\n[[Category:Articles with example code]]\\n[[Category:Automata (computation)]]\\n[[Category:Formal languages]]\\n[[Category:Pattern matching]]\\n[[Category:Programming constructs]]\""